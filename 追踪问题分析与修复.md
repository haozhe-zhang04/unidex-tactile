# 机械手食指追踪问题分析与修复

## 问题描述
设置了 `curr_finger_tip_goal_cart_global` 和 `curr_ee_goal_cart_world_offset`，但机械手的食指并没有追踪这个点。

## 问题根源分析

### 1. 控制流程梳理

**文件**: `legged_gym/scripts/train_wuji.py`
```python
ppo_runner.learn(...)  # 训练循环
```

**文件**: `legged_gym/envs/wuji/wuji_robot_pos_force.py`

#### 1.1 目标位置更新（第1000-1012行）
```python
def update_curr_ee_goal(self):
    # 更新目标位置（相对于基座的局部坐标）
    self.curr_finger_tip_goal_cart[:] = torch.lerp(...)
    # 存储到 commands 中（但未被使用！）
    self.commands[:, INDEX_TIP_POS_X_CMD:(INDEX_TIP_POS_Z_CMD+1)] = self.curr_finger_tip_goal_cart.view(self.num_envs,3)
```

#### 1.2 可视化中的计算（第575-580行）
```python
def _draw_ee_goal_curr(self):
    # 计算世界坐标系中的目标位置
    curr_finger_tip_goal_cart_global = quat_apply(self.base_quat, self.curr_finger_tip_goal_cart)+self.base_pos
    curr_ee_goal_cart_world_offset = forces_offset_global / self.gripper_force_kps + curr_finger_tip_goal_cart_global
    # 仅用于可视化，不用于控制！
```

#### 1.3 实际控制（第106-122行）
```python
def step(self, actions):
    for _ in range(self.cfg.control.decimation):
        # 只使用 actions 直接控制关节
        self.dof_pos_target[:,4:8] = actions[:,4:8] + self.dof_pos[:,4:8]
        self.gym.set_dof_position_target_tensor(self.sim, ...)
```

### 2. 核心问题

**关键发现**：
1. ❌ `curr_finger_tip_goal_cart_global` 和 `curr_ee_goal_cart_world_offset` **只被计算用于可视化**，没有被用于控制
2. ❌ `update_curr_ee_goal()` 将目标存储到 `commands` 中，但 `commands` **从未被读取用于控制**
3. ❌ 没有逆运动学（IK）求解器将笛卡尔坐标目标转换为关节角度
4. ❌ `control_ik()` 函数存在（第926行），但**从未被调用**
5. ✅ 实际控制只使用 `actions[:,4:8]` 直接更新关节目标

### 3. 数据流分析

```
训练循环 (PPO)
    ↓
step(actions)  # actions 来自策略网络
    ↓
dof_pos_target[:,4:8] = actions[:,4:8] + dof_pos[:,4:8]  # 直接控制关节
    ↓
set_dof_position_target_tensor()  # 应用到仿真

❌ curr_finger_tip_goal_cart_global 和 curr_ee_goal_cart_world_offset 完全被忽略！
```

## 解决方案

### 方案1：使用逆运动学将目标位置转换为关节角度

在 `step()` 函数中，将目标位置转换为关节角度：

```python
def step(self, actions):
    if not self.headless:
        self.render()
    
    # 计算目标位置（世界坐标）
    curr_finger_tip_goal_cart_global = quat_apply(self.base_quat, self.curr_finger_tip_goal_cart) + self.base_pos
    
    # 计算力偏移后的目标位置
    forces_local = self.sensors_forces[:, 0, :3]
    forces_cmd_local = self.current_Fxyz_finger_tips_cmd
    forces_offset_local = (forces_local + forces_cmd_local)
    forces_offset_global = quat_apply(self.base_quat, forces_offset_local)
    curr_ee_goal_cart_world_offset = forces_offset_global / self.gripper_force_kps + curr_finger_tip_goal_cart_global
    
    # 转换到基座坐标系（用于IK）
    target_pos_base = quat_rotate_inverse(self.base_quat, curr_ee_goal_cart_world_offset - self.base_pos)
    
    # 使用逆运动学计算关节角度
    # 方法1：使用 control_ik（需要先计算雅可比矩阵）
    # 方法2：使用 Pinocchio 的逆运动学
    # 方法3：使用简单的PD控制追踪目标位置
    
    for _ in range(self.cfg.control.decimation):
        # 使用IK计算关节目标
        joint_targets_ik = self._compute_ik_targets(target_pos_base)
        
        # 结合 actions 和 IK 结果
        self.dof_pos_target[:,4:8] = joint_targets_ik  # 或者混合：0.5 * joint_targets_ik + 0.5 * (actions[:,4:8] + self.dof_pos[:,4:8])
        
        self.gym.set_dof_position_target_tensor(self.sim, gymtorch.unwrap_tensor(self.dof_pos_target))
        # ... 其余代码
```

### 方案2：使用 Pinocchio 逆运动学

添加逆运动学求解函数：

```python
def _compute_ik_targets(self, target_pos_base):
    """
    使用 Pinocchio 逆运动学计算关节角度
    
    Args:
        target_pos_base: 目标位置（相对于基座坐标系），shape: (num_envs, 3)
    
    Returns:
        joint_targets: 关节角度目标，shape: (num_envs, 4)
    """
    joint_targets = torch.zeros(self.num_envs, 4, device=self.device)
    
    for i in range(self.num_envs):
        # 当前关节角度
        q_current = self.dof_pos[i, 4:8].cpu().double().numpy()
        
        # 使用 Pinocchio 逆运动学
        # 注意：需要设置目标frame ID（finger_tip）
        target_pos = target_pos_base[i].cpu().double().numpy()
        
        # 使用 damped least squares 或 Levenberg-Marquardt
        # 这里需要实现完整的IK求解器
        # 或者使用现有的 control_ik 函数
        
    return joint_targets
```

### 方案3：使用雅可比矩阵和 control_ik

修改 `step()` 函数，使用现有的 `control_ik()` 函数：

```python
def step(self, actions):
    if not self.headless:
        self.render()
    
    # 计算目标位置
    curr_finger_tip_goal_cart_global = quat_apply(self.base_quat, self.curr_finger_tip_goal_cart) + self.base_pos
    forces_local = self.sensors_forces[:, 0, :3]
    forces_cmd_local = self.current_Fxyz_finger_tips_cmd
    forces_offset_local = (forces_local + forces_cmd_local)
    forces_offset_global = quat_apply(self.base_quat, forces_offset_local)
    curr_ee_goal_cart_world_offset = forces_offset_global / self.gripper_force_kps + curr_finger_tip_goal_cart_global
    
    # 获取当前末端位置（世界坐标）
    current_ee_pos_world = self.rigid_state[:, self.finger_tips_idx, :3].squeeze(1)
    
    # 计算位置误差（世界坐标）
    pos_error_world = curr_ee_goal_cart_world_offset - current_ee_pos_world
    
    # 转换到基座坐标系
    pos_error_base = quat_rotate_inverse(self.base_quat, pos_error_world)
    
    # 计算雅可比矩阵（需要实现）
    # self.ee_j_eef = self._compute_jacobian()  # shape: (num_envs, 6, num_dofs)
    
    # 使用 control_ik 计算关节增量
    # dpose = torch.cat([pos_error_base, torch.zeros(self.num_envs, 3, device=self.device)], dim=1)  # 6D: 3D pos + 3D orn
    # joint_deltas = self.control_ik(dpose)  # 只取前4个关节
    
    for _ in range(self.cfg.control.decimation):
        # 方法A：完全使用IK
        # self.dof_pos_target[:,4:8] = self.dof_pos[:,4:8] + joint_deltas[:,4:8]
        
        # 方法B：混合使用 actions 和 IK
        # self.dof_pos_target[:,4:8] = 0.7 * (self.dof_pos[:,4:8] + joint_deltas[:,4:8]) + 0.3 * (actions[:,4:8] + self.dof_pos[:,4:8])
        
        # 方法C：当前方式（仅使用 actions）
        self.dof_pos_target[:,4:8] = actions[:,4:8] + self.dof_pos[:,4:8]
        
        self.gym.set_dof_position_target_tensor(self.sim, gymtorch.unwrap_tensor(self.dof_pos_target))
        # ... 其余代码
```

## 推荐实现步骤

### 步骤1：添加雅可比矩阵计算

```python
def _compute_jacobian(self):
    """
    计算末端执行器的雅可比矩阵
    
    Returns:
        j_eef: 雅可比矩阵，shape: (num_envs, 6, num_dofs)
    """
    j_eef = torch.zeros(self.num_envs, 6, self.num_dofs, device=self.device)
    
    for i in range(self.num_envs):
        q_i = self.dof_pos[i].cpu().double().numpy()
        
        # 使用 Pinocchio 计算雅可比矩阵
        pin.computeJointJacobians(self.pinocchio_model, self.pinocchio_data, q_i)
        pin.updateFramePlacements(self.pinocchio_model, self.pinocchio_data)
        
        # 获取 finger_tip 的雅可比矩阵
        frame_id = self.pinocchio_tips_idx[1]  # 食指
        jacobian = pin.getFrameJacobian(
            self.pinocchio_model, 
            self.pinocchio_data, 
            frame_id, 
            pin.LOCAL_WORLD_ALIGNED
        )
        
        j_eef[i] = torch.from_numpy(jacobian).to(self.device).float()
    
    return j_eef
```

### 步骤2：修改 step() 函数

在 `step()` 函数中添加IK控制：

```python
def step(self, actions):
    if not self.headless:
        self.render()
    
    # 计算目标位置（世界坐标）
    curr_finger_tip_goal_cart_global = quat_apply(self.base_quat, self.curr_finger_tip_goal_cart) + self.base_pos
    
    # 计算力偏移
    forces_local = self.sensors_forces[:, 0, :3]
    forces_cmd_local = self.current_Fxyz_finger_tips_cmd
    forces_offset_local = (forces_local + forces_cmd_local)
    forces_offset_global = quat_apply(self.base_quat, forces_offset_local)
    curr_ee_goal_cart_world_offset = forces_offset_global / self.gripper_force_kps + curr_finger_tip_goal_cart_global
    
    # 获取当前末端位置
    current_ee_pos_world = self.rigid_state[:, self.finger_tips_idx, :3].squeeze(1)
    
    # 计算位置误差（世界坐标）
    pos_error_world = curr_ee_goal_cart_world_offset - current_ee_pos_world
    
    # 转换到基座坐标系
    pos_error_base = quat_rotate_inverse(self.base_quat, pos_error_world)
    
    # 计算雅可比矩阵
    self.ee_j_eef = self._compute_jacobian()
    
    # 使用 control_ik 计算关节增量（只使用位置，不考虑姿态）
    dpose = torch.cat([pos_error_base, torch.zeros(self.num_envs, 3, device=self.device)], dim=1)
    joint_deltas = self.control_ik(dpose)
    
    # actions为 delta action
    for _ in range(self.cfg.control.decimation):
        # 混合使用 IK 和 actions
        ik_control = self.dof_pos[:,4:8] + joint_deltas[:,4:8]
        action_control = actions[:,4:8] + self.dof_pos[:,4:8]
        
        # 可以选择完全使用IK，或者混合
        self.dof_pos_target[:,4:8] = ik_control  # 或者：0.5 * ik_control + 0.5 * action_control
        
        self.gym.set_dof_position_target_tensor(self.sim, gymtorch.unwrap_tensor(self.dof_pos_target))
        
        if self.global_steps > self.cfg.commands.force_start_step * 24:
            self._push_finger_tip(torch.arange(self.num_envs, device=self.device))
        
        self.gym.apply_rigid_body_force_tensors(self.sim, gymtorch.unwrap_tensor(self.forces[:,:,:3].reshape(-1, 3).contiguous()), None, gymapi.LOCAL_SPACE)
        self.gym.simulate(self.sim)
        self.gym.refresh_dof_state_tensor(self.sim)
    
    self.post_physics_step()
    # ... 其余代码
```

## 总结

**问题根源**：
- 目标位置被计算了，但没有被转换为关节角度
- 控制只使用 `actions`，完全忽略了目标位置

**解决方案**：
1. 实现雅可比矩阵计算
2. 使用 `control_ik()` 将目标位置转换为关节增量
3. 在 `step()` 中使用IK结果更新 `dof_pos_target`

**注意事项**：
- 需要确保坐标系转换正确
- IK求解可能不稳定，需要添加阻尼
- 可以混合使用IK和actions，让策略网络学习如何配合IK控制

